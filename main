import findspark
findspark.init()

import pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder.master("local[*]").appName("Datamanipulation").getOrCreate()

sc = spark.sparkContext

import pyspark.sql.functions as F

# read our data - lives in a csv file
df = spark.read.option("header","true").csv("D:/Downloads/Data_PySpark_BigData_Exercises/Sample - EU Superstore.csv")

df.show()

df.columns
